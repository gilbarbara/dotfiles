# Global Instructions for Claude Code

## Core Principles
- Extremely concise communication; sacrifice grammar for brevity
- Prioritize simplicity, minimal changes; work within existing patterns
- Ask clarifying questions if unclear; consider simplest solution first
- Maintain existing architecture, follow established patterns, ensure TypeScript safety
- Target specific problems without changing overall approach
- **Fix works? Apply the pattern immediately.** Worked before [change]? Fix related to that change
- **Empirical evidence > theory.** Apply what works, explain only if asked
- No time estimates (typically 10-15x overestimated). Detailed validation → fast, correct execution
- End each plan with a list of unresolved questions (extremely concise)

## Tools
- Use `fd` instead of `find`
- Use `rg` instead of `grep`
- Use `eza` instead of `tree`

## Critical Rules
- If context running out, continue after compact
- QUALITY OVER SPEED. Don't rush, don't worry about tokens
- Never change source code while working with tests
- Never end test task with broken/failing tests
- Vitest globals enabled; don't import vitest in tests
- Never start Docker before checking if already running (check `docker ps` first)
- Check API response structure before/after `jq` - many APIs return 200 with errors in body. Empty jq result might be error response, not empty data

## Verify Before Create
**Core Rule**: Read actual code before writing dependent code.

**Before writing any dependent code:**
- **Existence**: Functions, classes, API endpoints, DB fields, config, env vars
- **Interfaces**: Signatures, return types, data structures, event payloads
- **Method**: Grep/glob or Task+Explore → read → verify interface → write

**Never**:
- Tests for non-existent functions
- API clients for non-existent endpoints
- UI consuming non-existent data fields
- DB queries for non-existent columns
- Imports of non-created modules

**Codebase is the source of truth. Mental model suspect until verified.**

## Research Protocol
**When designing solutions or exploring unfamiliar patterns:**
- Read existing implementation FIRST (always primary)
- Use Exa (`get_code_context_exa`) for ecosystem best practices, real-world examples
- Verify patterns match established standards for the library/framework
- Identify edge cases and failure modes upfront
- Confirm compatibility with existing systems
- **Production-ready only** - no workarounds, temporary fixes, or "we'll fix later"

## Validation Discipline
**Assumptions = failures. Red flags:**
- "I think", "should", "probably", "usually" → you're guessing

**For complex changes:**
- Compare similar patterns systematically (use tables/lists for consistency)
- Trace execution: caller → target → callees → side effects
- Mental execution before running tests
- One bug → check all similar places
- Zero tolerance: ANY failure = incomplete

## Testing

  ### Test Writing Protocol

  BEFORE writing ANY test:
  1. Read actual implementation (signatures, imports, behavior)
  2. Ask user: "Found X in code. Test Y?"
  3. Write test only after confirmation

  If test fails: STOP → investigate → ask before proceeding

  Test Validation Checkpoint (after each test file):
  - Run ONLY that file
  - ANY failure → STOP → report before continuing

### Workflow & Structure
- Tests in `test/` mirroring `src/` structure
- Run existing tests before changes; check for reusable mocks
- Update imports immediately when renaming files/classes
- Fix one error type at a time: imports → types → logic
- Run full test suite + TypeScript check after changes

### Patterns
- Descriptive `describe()` blocks; nested for grouping
- Names: "should [behavior] when [condition]"
- Mock all external deps: `vi.fn()` (Vitest) / `jest.fn()` (Jest)
- `beforeEach()` for setup/fresh mocks; `afterEach()` for cleanup (`vi.clearAllMocks()`)
- `afterAll()` with `vi.restoreAllMocks()` to restore originals
- Mock modules: `vi.spyOn()` / `jest.spyOn()`

### Vitest-Specific
- `vi.spyOn(global, 'setTimeout')` for time-based functions
- Import jest-extended matchers in setup
- `vi.useFakeTimers()` for dates; `vi.useRealTimers()` in `afterEach()`

### Critical Patterns
- `it.each()` for data-driven tests with type-safe interfaces
- Test error scenarios alongside happy paths
- Verify exact error messages/codes; `expect().rejects.toThrow()`
- Test edge cases: leap years, month boundaries, etc.
- One assertion when possible, multiple for related behavior
- Verify calls: `expect().toHaveBeenCalledWith()`
- Use `@ts-expect-error` for testing invalid TS scenarios
- Mock complex business logic deps; avoid testing implementation details

## Development Workflow

  ### Definition of "Done" - MANDATORY CHECKLIST

  Code is NOT done until you verify ALL of these IN ORDER:
  ☐ 1. Code compiles (run it!)
  ☐ 2. Tests pass (run them! ALL must pass!)
  ☐ 3. Lint passes (run it!)
  ☐ 4. Typecheck passes (run it!)
  ☐ 5. Application starts (run it!)

  If ANY fails → NOT DONE → STOP → FIX IT.

### Validation Rhythm
Run at checkpoints:
- After significant service/module
- After feature/route group
- Before claiming ANY phase "done"
- When things feel broken (stop and validate)

**CRITICAL: Fix issues immediately. Don't accumulate broken state.**

### Error Handling
- Implement at the **service layer**, not just routes/controllers
- Include audit/logging in BOTH success AND failure paths
- Services handle own errors before throwing
- Never let audit logs depend on success-only flow

### Reality Check
Before claiming completion:
- Can I run this code now?
- Would I deploy to production?
- Have I verified it works, or just written it?
- Is this production-ready, or just a workaround?

**Working code > documentation about non-working code.**
**Production-ready solutions > temporary fixes.**

### Documentation Discipline
**Create**: README.md, API docs, deployment guides (user-facing)
**Never Create**: IMPLEMENTATION_*.md, PROGRESS_*.md, TYPESCRIPT_ISSUES.md (process-tracking)

## Tooling & Configuration

### Standard Script Patterns
- `build`: `"npm run clean && tsup"` (always clean first)
- `clean`: `"del dist/*"` (cross-platform via del-cli)
- `watch`: Build in watch mode
- `validate`: `"npm run lint && npm run typecheck && npm run test:coverage && npm run build"`
- `format`: `"prettier \"**/*.{css,graphql,json,less,md,mdx,scss,yaml,yml}\" --write"`
- `test`: Basic runner
- `test:coverage`: Tests with coverage
- `test:watch`: Interactive watching
- `lint`: ESLint on src
- `typecheck`: TS compiler check
- `size`: Bundle size monitoring (frontend only)

### TypeScript Configuration
- **Base**: Extend `@gilbarbara/tsconfig`
- **Path Mapping**: `~/*` alias → `src/*`
- **Target/Module**: `ESNext` target, `bundler` module resolution
- **Global Types**: Include `vitest/globals`, `jest-extended`
- **Include**: `globals.d.ts` and `src/**/*`

### TypeScript Preferences
- Avoid non-null assertions, casting, `any` (only if no alternative)
- Use interfaces for object shapes
- Rely on type inference; explicit when clarity matters
- Prefer utility types (`Pick<T, K>`, `Omit<T, K>`) over manual interfaces
- Favor functional patterns over classes

### Git Hooks (Husky)
- **pre-commit**: `./node_modules/.bin/repo-tools check-remote && npm run validate`
  - Checks remote status + runs full validation before commits
- **post-merge**: `./node_modules/.bin/repo-tools install-packages`
  - Auto-installs/updates packages after merges
- **prepare**: `husky` - Initialize during npm install

### Quality Tools Ecosystem
- **ESLint**: Extend `@gilbarbara/eslint-config` (or `/base` excluding React) and `@gilbarbara/eslint-config/vitest`
- **Prettier**: Use `@gilbarbara/prettier-config`
- **TypeScript**: Extend `@gilbarbara/tsconfig`
- **size-limit**: Monitor bundle sizes (frontend only)
- **tsup**: Modern TS bundler with dual CJS/ESM
- **del-cli**: Cross-platform file deletion
- **repo-tools**: `check-remote` for branch status, `install-packages` for deps

## Planning & Execution

### Before Making Changes
1. Read and understand FULL scope
2. Identify all affected components and relationships
3. Identify edge cases and failure modes
4. Confirm compatibility with existing systems
5. Create clear plan with specific steps
6. Ask clarifying questions if scope unclear
7. Make targeted, precise edits vs bulk replacements

### Database Schema Changes
1. Distinguish primary vs foreign keys (different naming conventions)
2. Map all relationships before changes
3. Change one component at a time; verify compiles before next
4. Never bulk find/replace property names without context

### Execution Control
- STOP and ask if unsure about scope
- Make minimal, targeted changes vs sweeping mods
- Test after each logical group vs at end
- If making same edit across many files, pause and reconsider

## Change Process
- Show proposed changes clearly before implementing
- Focus only on files needing modification
- Provide reasoning for non-obvious changes (keep brief)
- Ask permission when switching problem domains

## Communication
- Skip trivial edit comments
- Mention testing needs or potential side effects
- Don't hallucinate data - ask for real examples when needed
- Remind with 'KISS' if I'm overcomplicating
