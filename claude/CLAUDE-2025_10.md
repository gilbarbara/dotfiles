# Global Instructions for Claude Code



## Core Approach
- In all interactions and commit messages, be extremely concise and sacrifice grammar for the sake of concision.
- Prioritize simplicity and minimal changes over completeness (doesn't mean ignoring the scope or leaving errors behind ).
- Work within existing patterns - avoid suggesting rewrites
- Ask clarifying questions if requirements are unclear
- Consider the simplest solution first
- At the end of each plan, give me a list of unresolved questions to answer, if any. Make the questions extremely concise. Sacrifice grammar for the sake of concision.

## Code Standards
- Maintain existing architecture and code structure
- Follow established patterns and style
- Ensure TypeScript type safety
- Target specific problems without changing the overall approach

## Tools

- Use `fd` instead of `find`
- Use `rg` instead of `grep`
- Use `eza` instead of `tree`

## CRITICAL

- If the context is running out, don't rush things; let's continue after the compact.
- QUALITY OVER SPEED. Don't waste time, but don't worry about tokens.
- Never change source code while working with tests.
- Never end a test task with broken or failing tests.
- Don't use `jq` for parsing asynchronous requests unless you are sure you understand the contract. 
- You don't need to import vitest in tests. It's global
- Never attempt to start Docker before checking if it is already running.
- Use MultiEdit instead of multiple parallel edits.

## Problem-Solving Approach
  - **Fix works? Apply the pattern immediately.** Don't re-analyze similar
      issues.
  - **"Worked before [change]"? Simple fix related to that change.** Don't
      theorize alternatives.
  - **Empirical evidence > theory.** Apply what works, explain only if
    asked.

 ## CRITICAL: Verify Before Create

  **BEFORE writing any code that depends on existing code:**

  ### 1. Existence Check
  - **Functions/Methods**: Grep or read to verify the function actually exists
  - **Classes/Types**: Check the actual definition before using
  - **API Endpoints**: Verify the route exists in the backend
  - **Database Fields**: Check the actual schema/model
  - **Config Options**: Verify in actual config files
  - **Environment Variables**: Check .env files or settings

  ### 2. Interface Validation
  - **Function Signatures**: Verify parameter names, types, and order
  - **Return Types**: Check what's actually returned, not what should be returned
  - **Data Structures**: Read the actual code to see field names
  - **Event Payloads**: Check producer code for actual fields sent

  ### 3. The Rule
  ❌ NEVER: Write code based on assumptions about what exists
  ✅ ALWAYS: Read the actual code first, then write dependent code

  ### 4. Common Mistakes to Avoid
  - Writing tests for functions that don't exist yet
  - Creating API clients that expect endpoints that aren't implemented
  - Building UI components that consume data fields that aren't sent
  - Writing database queries for columns that don't exist
  - Importing modules/functions that haven't been created

  ### 5. The Workflow
  1. User requests: "Add tests for the authentication module"
  2. ❌ BAD: Start writing tests immediately
  3. ✅ GOOD:

    - First: Read the authentication module to see what functions exist
    - Then: Write tests for those actual functions
    - Finally: If functions are missing, note that and discuss with user

  ### 6. When You Catch Yourself Assuming
  **Stop and ask:**
  - "Does this function/class/endpoint actually exist?"
  - "Have I read the actual code, or am I guessing?"
  - "What does the source code actually show?"

  **Then:**
  - Grep/glob to find it
  - Read the actual implementation
  - Verify the interface matches your assumptions

  ## Remember
  **The codebase is always the source of truth. Your mental model is always suspect until 
  verified.**

  This covers:
  - Tests for non-existent functions
  - API clients expecting non-existent endpoints
  - UI expecting data that isn't sent
  - Database queries for non-existent columns
  - Any code that depends on something else existing

  The key principle: Read first, write second.

## TypeScript Preferences

- Don't use non-null assertions or casting and `any`. Only if there's no other way around it
- Use interfaces for object shapes
- Rely on type inference, but be explicit when clarity matters
- Prefer utility types (Pick<T, K>, Omit<T, K>) over manual interfaces
- Favor functional patterns over classes

## TypeScript Configuration Standards

- **Base Configuration**: Always extend from `@gilbarbara/tsconfig`
- **Path Mapping**: Use `~/*` alias pointing to `src/*` for cleaner imports
- **Target/Module**: Use `ESNext` target with `bundler` module resolution for modern builds
- **Global Types**: Include `vitest/globals` and `jest-extended` in types array
- **Project Structure**: Include both `globals.d.ts` and `src/**/*` in include array

## Git Hooks (Husky)

### Standard Hook Setup
- **pre-commit**: `./node_modules/.bin/repo-tools check-remote && npm run validate`
  - Checks remote status and runs full validation pipeline before commits
- **post-merge**: `./node_modules/.bin/repo-tools install-packages`
  - Automatically installs/updates packages after merging branches
- **prepare**: `husky` - Initialize Husky hooks during npm install

### repo-tools Integration
- Use `repo-tools check-remote` to verify branch is up-to-date before commits
- Use `repo-tools install-packages` for automatic dependency management

## Quality Tools Ecosystem

### @gilbarbara Configuration Stack
- **ESLint**: Extend with `@gilbarbara/eslint-config` (or @gilbarbara/eslint-config/base ` that exclude react) and `@gilbarbara/eslint-config/vitest`
- **Prettier**: Use `@gilbarbara/prettier-config` for consistent formatting
- **TypeScript**: Extend `@gilbarbara/tsconfig` for standardized TS configuration

### Bundle & Quality Monitoring
- **size-limit**: Monitor bundle sizes (applicable for frontend code only)
- **tsup**: Modern TypeScript bundler with dual CJS/ESM output
- **del-cli**: Cross-platform file deletion utility

## Planning Requirement
Before making any changes:
1. **Read and understand the FULL scope** of the requested change
2. **Identify all affected components** and their relationships
3. **Create a clear plan** with specific steps before executing
4. **Ask clarifying questions** if the scope is unclear
5. **Make targeted, precise edits** rather than bulk replacements

Specific for Database/Model Changes

## Database Schema Changes
When changing database schemas:
1. **Distinguish between primary keys vs foreign keys** - they often
    have different naming conventions
2. **Map out all relationships** before making changes
3. **Change one component at a time** and verify it compiles before
    moving to the next
4. **Never use bulk find/replace** for property names without
    understanding context

## Execution Control
- **STOP and ask for clarification** if you're unsure about the scope
- **Make minimal, targeted changes** rather than sweeping
  modifications
- **Test after each logical group of changes** rather than at the end
- **If you find yourself making the same type of edit across many 
  files, pause, and reconsider the approach**

The key addition might be something like:
"Before making any code changes, explain your understanding of the
full scope and get confirmation before proceeding."

## Implementation Standards

### Definition of "Done"
Code is only complete when ALL of these pass:
- Code written and compiles
- Tests pass (run them!)
- Validation passes (lint + typecheck)
- Application/service actually starts

If you can't run the validation pipeline successfully, it's not done.

### Error Handling Architecture
- Implement error handling at the **service layer**, not just in routes/controllers
- Include audit/logging in BOTH success AND failure paths
- Services should handle their own errors before throwing
- Never let audit logs depend on success-only execution flow

### Validation Rhythm
Run validation at logical checkpoints:
- After completing a significant service or module
- After completing a feature or route group
- Before claiming ANY phase is "done"
- When things feel broken (stop and validate)

Fix issues immediately when found. Don't accumulate broken state.

### Reality Check
Before claiming completion, ask yourself:
- Can I actually run this code right now?
- Would I deploy this to production?
- Have I verified it works, or just written it?

Working code > documentation about non-working code.

## Change Process
- Show proposed changes clearly before implementing
- Focus only on files that need modification
- Provide reasoning for non-obvious changes (keep brief)
- Ask permission when switching problem domains

## Communication
- Skip trivial edit comments
- Mention testing needs or potential side effects
- Don't hallucinate data - ask for real examples when needed
- Remind with 'KISS' if I'm overcomplicating

## Testing Best Practices

### Testing Workflow
**Before Making Changes**
1. Check test directory structure - tests should mirror source structure
2. Run existing tests first to ensure they pass
3. Check for reusable mocks in test fixtures

**During Development**
1. Update ALL imports immediately when renaming files or classes
2. Run TypeScript check after structural changes
3. Run tests frequently to catch errors early
4. Fix one type of error at a time (imports, then types, then test logic)

**After Changes**
1. Run the full test suite for the affected modules
2. Run TypeScript check
3. Run linting
4. Verify coverage if applicable.

### Unit Testing Patterns

**Test Structure & Organization**
- Tests in `test/` directory mirroring `src/` structure
- Use descriptive `describe()` blocks for each method/functionality
- Group related test cases using nested `describe()` blocks
- Test names follow: "should [expected behavior] when [condition]"

**Mocking & Setup**

- Mock all external dependencies using `vi.fn()` (Vitest) or `jest.fn()` (Jest)
- Use `beforeEach()` for common setup and creating fresh mocks
- Use `afterEach()` for cleanup with `vi.clearAllMocks()` or `jest.clearAllMocks()`
- Use `afterAll()` with `vi.restoreAllMocks()` to restore original implementations
- Prefer manual mocks over auto-mocking for better control
- Mock external modules using `vi.spyOn()` or `jest.spyOn()`

**Vitest-Specific Patterns**
- Use `vi.spyOn(global, 'setTimeout')` for testing time-based functions
- Import jest-extended matchers in setup files for enhanced assertions
- Enable Vitest globals in configuration for cleaner test syntax

**Data-Driven Testing**
- Use `it.each()` for testing multiple scenarios with different inputs
- Define test case interfaces for better type safety
- Group test cases by validation type (valid, invalid, edge cases)
- Include descriptive names in test case objects

**Error Handling Testing**
- Always test error scenarios alongside happy paths
- Verify exact error messages and status codes
- Use `expect().rejects.toThrow()` for async error testing
- Test specific error types with expected properties

**Time & Date Testing**
- Use `vi.useFakeTimers()` or `jest.useFakeTimers()` for deterministic date testing
- Clean up timers with `vi.useRealTimers()` in `afterEach()`
- Test edge cases like leap years and month boundaries
- Use fixed dates for consistent test results

**Coverage Expectations**
- Aim for high test coverage, though specific thresholds vary by project
- Focus on critical paths and edge cases rather than arbitrary percentage targets
- Use coverage reports to identify untested code paths

**Best Practices**
- One assertion per test when possible, multiple when testing related behavior
- Use meaningful mock data from constants/fixtures
- Test both successful operations and failure scenarios
- Verify method calls with `expect().toHaveBeenCalledWith()`
- Use `@ts-expect-error` comments when testing invalid TypeScript scenarios
- Keep tests focused and avoid testing implementation details
- Mock complex business logic dependencies rather than testing integration

## Development Workflow

### Standard Validation Pipeline
Always run the complete validation sequence as the last step in a todo list:
1. `npm run lint` - Code quality check
2. `npm run typecheck` - TypeScript compilation check  
3. `npm run test:coverage` - Test execution with coverage
4. `npm run build` - Build verification

### Quality Gates
- Pre-commit hooks prevent commits without passing validation
- Post-merge hooks automatically handle dependency updates
- Comprehensive script pipeline ensures consistent quality standards